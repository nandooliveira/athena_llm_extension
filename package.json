{
  "name": "athenallm",
  "displayName": "Athena LLM",
  "description": "",
  "version": "0.0.1",
  "engines": {
    "vscode": "^1.79.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "athena_llm.startNewSession",
        "title": "Start a new Session"
      }
    ],
    "configuration": {
      "title": "Athena LLM",
      "properties": {
        "Athena LLM.apiKey": {
          "type": "string",
          "default": "",
          "description": "API Key"
        },
        "Athena LLM.apiAddress": {
          "type": "string",
          "default": "https://api.openai.com/v1/chat/completions",
          "description": "API URL"
        },
        "Athena LLM.model": {
          "type": "string",
          "default": "gpt-4",
          "description": "Model"
        },
        "Athena LLM.maxTokens": {
          "type": "number",
          "default": 1000,
          "description": "Maximum number of tokens allowed for suggestion responses."
        },
        "Athena LLM.temperature": {
          "type": "number",
          "default": 0.9,
          "description": "Model's temperature setting."
        },
        "Athena LLM.numberOfSuggestions": {
          "type": "number",
          "default": 3,
          "description": "Desired number of suggestions to be received from the model."
        },
        "Athena LLM.contextSize": {
          "type": "number",
          "default": 3,
          "description": "Number of lines of code to be sent to the model for contextualizing the prompt."
        },
        "Athena LLM.serverAddress": {
          "type": "string",
          "default": "http://localhost:8000",
          "description": "The server address where the collected data will be sent for the application."
        },
        "Athena LLM.enableTelemetry": {
          "type": "boolean",
          "default": false,
          "description": "Enable/disable sending telemetry data."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/mocha": "^10.0.1",
    "@types/node": "20.2.5",
    "@types/vscode": "^1.79.0",
    "@typescript-eslint/eslint-plugin": "^5.59.8",
    "@typescript-eslint/parser": "^5.59.8",
    "@vscode/test-electron": "^2.3.2",
    "eslint": "^8.41.0",
    "glob": "^8.1.0",
    "mocha": "^10.2.0",
    "typescript": "^5.1.3"
  },
  "dependencies": {
    "axios": "^1.5.1",
    "openai": "^4.11.0",
    "uuid": "^9.0.1"
  }
}
